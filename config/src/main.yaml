data:
  data_path: data/nq/parametric_relevance_tagged/validation.json
  max_seq_length: 1024
  use_single_context: True


model:
  model_name: meta-llama/Llama-3.1-8B-Instruct
  gen_kwargs:
    do_sample: False
    temperature: 1.0
    top_p: 1
    top_k: null
    max_new_tokens: 256
  prune:
    ratio: 0.3

self_task_prompt_name: base
generate_prompt_name: base
output_dir: src/results/main
task: base
experiment_name: